{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics\n",
    "\n",
    "\n",
    "* build ML prototype that will predict if a question will be ansered in the next 30 minutes\n",
    "* model it as a binary classification\n",
    "* first prepare simple model with some basic features\n",
    "* then try to improve it by adding some more features\n",
    "* use random forest as a classifier\n",
    "* for modelling consider only questions that have accepted answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, unix_timestamp, when, lit, length, array_sort, udf, desc\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.ml.feature import VectorAssembler, Tokenizer, SQLTransformer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Predictive Analytics')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')\n",
    "\n",
    "users_input_path = os.path.join(project_path, 'data/users')\n",
    "\n",
    "questions_input_path = os.path.join(project_path, 'data/questions-json')\n",
    "\n",
    "model_output_path = os.path.join(project_path, 'output/models/binary-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load the data:</b>\n",
    "\n",
    "Hint:\n",
    "load all three datasets: anwers, questions, users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', answers_input_path)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "questionsDF = (\n",
    "    spark\n",
    "    .read.format('json')\n",
    "    .option('path', questions_input_path)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "usersDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .option('path', users_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Add label to the dataset</b>\n",
    "\n",
    "hint:\n",
    "* join questions with answers on `accepted_anser_id`\n",
    "* join also with users on `user_id`\n",
    "* compute response time using unix_timestamp or cast the timestamps to long\n",
    "  * for questions you first need to cast the `creation_date` to timestamp if it is a string\n",
    "* use 'when' condition to compute the label (when response time <= 1800 then 1 otherwise 0)\n",
    "* cache the DataFrame for faster access in next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Take a look at the distribution of classes</b>\n",
    "\n",
    "Hint\n",
    "* group by label and do the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Add some basic features:</b>\n",
    "\n",
    "hint:\n",
    "* add feature 'title_complexity'\n",
    " * compute the length of the question title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prepare data</b>\n",
    "\n",
    "hint:\n",
    "* split the data for training and testing using [randomSplit](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.randomSplit.html#pyspark.sql.DataFrame.randomSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Build the pipeline and train the model:</b>\n",
    "\n",
    "hint:\n",
    "* use: \n",
    " * [VectorAssembler](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html#pyspark.ml.feature.VectorAssembler)\n",
    " * [RandomForestClassifier](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.RandomForestClassifier.html#pyspark.ml.classification.RandomForestClassifier)\n",
    " * [Pipeline](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.Pipeline.html#pyspark.ml.Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluate the model</b>\n",
    "\n",
    "hint:\n",
    "* use [BinaryClassificationEvaluator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.evaluation.BinaryClassificationEvaluator.html#pyspark.ml.evaluation.BinaryClassificationEvaluator) with areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add more features\n",
    "\n",
    "Hint:\n",
    "* add features: \n",
    "  * `question_size` number of words in the question body\n",
    "     * use [Tokenizer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.Tokenizer.html#pyspark.ml.feature.Tokenizer) to split the text on words\n",
    "     * use a [SQLTransformer](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.SQLTransformer.html#pyspark.ml.feature.SQLTransformer) to compute the size\n",
    "    * you can try to add a bunch of other features such as reputation, upvotes, downvotes of the user and so on\n",
    "* train the model with this new pipeline\n",
    "* evaluate the model\n",
    "* see if the model improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the importance of the features\n",
    "\n",
    "Hint\n",
    "* access the last stage of the model to get the instance of the RandomForestClassificationModel\n",
    "  * use model.stages\n",
    "* see [featureImportances](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.RandomForestClassificationModel.html#pyspark.ml.classification.RandomForestClassificationModel.featureImportances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning:\n",
    "\n",
    "hint:\n",
    "* use [ParamGridBuilder](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.ParamGridBuilder.html#pyspark.ml.tuning.ParamGridBuilder) to find optimal `numTrees` and optimal `maxDepth`\n",
    "* after you fit the [CrossValidator](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html) access the best model as `cross_model.bestModel`\n",
    "* compute the accuracy using the evaluator on the predictions computed by the bestModel\n",
    "\n",
    "Note:\n",
    "\n",
    "If you run in local mode make the grid just 2 x 2 to avoid long run (3 x 3 can run over an hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the params of the model\n",
    "\n",
    "Hint\n",
    "* see `avgMetrics` of the cross_model\n",
    "* see the stages of the bestModel\n",
    "  * access the last stage to get the instance of the `RandomForestClassificationModel`\n",
    "* see:\n",
    "  * `getNumTrees`\n",
    "  * `getMaxDepth()`\n",
    "  * `toDebugString` to see full description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model so you can use it later in some ml application\n",
    "\n",
    "* use [write](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.PipelineModel.html#pyspark.ml.PipelineModel.write) on the [PipelineModel](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.PipelineModel.html#pyspark.ml.PipelineModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
