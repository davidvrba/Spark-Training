{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43027e1e",
   "metadata": {},
   "source": [
    "## What is the probability a user will answer at least k questions next year?\n",
    "\n",
    "In this notebook we will see how Pandas user defined functions can be used for statistical modeling using [scipy](http://scipy.github.io/devdocs/reference/index.html) package. \n",
    "\n",
    "You will:\n",
    "* prepare the input data using aggregation\n",
    "* use vanilla UDF to compute the probability using Poisson distribution\n",
    "* use Pandas UDF to compute the probability using Poisson distribution\n",
    "* compare performance of both UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, lit, count, year, pandas_udf, avg, desc\n",
    "\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Statistical Modeling')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "answers_input_path = os.path.join(project_path, 'data/answers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c472de",
   "metadata": {},
   "source": [
    "## Task\n",
    "For each user compute probability that the user is going to answer 5 questions in the next year. Use simple model based on poisson distribution.\n",
    "\n",
    "* Create a DataFrame with two cols: user_id, answers, where the second is the average number of questions the user answered per year in the past.\n",
    "* Find out what is the last year and filter it out as it is incomplete.\n",
    "* Implement UDF that will use poisson distribution from scipy package to compute the probability that if the user answered n questions per year, he will answer at least 5 questions in the next year\n",
    "* Implement the UDF again, but this time as Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will need answers dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc46ed0",
   "metadata": {},
   "source": [
    "## Create input DataFrame\n",
    "* first find out what is the last year and filter it out as it is incomplete\n",
    "* filter for rows where user_id is not null\n",
    "* compute average number of answers per user and year\n",
    "  * group by user and year\n",
    "  * use count to see how many questions each user answered in each year\n",
    "  * group by again but now only per user\n",
    "  * compute the average per year for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b347ab-6b92-4441-a416-2b557d83e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what is the last year:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771a3d3",
   "metadata": {},
   "source": [
    "## Define a python function\n",
    "### Hint:\n",
    "\n",
    "* it should take as argument year_average and return the probability that at least `k` questions will be answered in next year\n",
    "* use [cdf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html#scipy.stats.poisson) function of the poisson in scipy\n",
    "* define `k` to be a constant equal 5\n",
    "* test if the function works\n",
    "* to calculate the probability use 1 - poisson.cdf(k=4, mu) as the cumulative distribution function gives P(X<=k) but we need P(X>=k) so we must compute the cumulative probability for k=4 and subtract it from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d1357-05a2-4317-9aee-234f67b87de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the function:\n",
    "\n",
    "k = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934c625-681e-480b-a079-3983a6035fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9efc0a0",
   "metadata": {},
   "source": [
    "## Define the UDF:\n",
    "### Hint:\n",
    "\n",
    "* once you have the python function, make the UDF from it. See udf in [docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html#pyspark.sql.functions.udf)\n",
    "* the return type will be float, since we will compute probability\n",
    "* make sure to use the `float()` function for the return value to cast it to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ec468",
   "metadata": {},
   "source": [
    "## Apply the udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377dbc06",
   "metadata": {},
   "source": [
    "## Try it with Pandas\n",
    "* create local Pandas dataframe with input data\n",
    "  * this will be for testing the Pandas function so you can sample the spark dataframe to get just some rows for testing\n",
    "  * see sample in [docs](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.sample.html)\n",
    "* pass a local Pandas series to poisson to see what it returns\n",
    "* define a function that will take pandas series as input argument and will return also pandas series\n",
    "\n",
    "### Hint:\n",
    "\n",
    "* create a pandas series from pandas dataframe as `local_data['answers']`, where local_data is pd_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local pd dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1386b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the poisson.cdf returns if we pass in Pandas series:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily create a pandas series from the numpy array:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf8855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now define a function from it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4356586f",
   "metadata": {},
   "source": [
    "### Hint\n",
    "\n",
    "* Once you have the function make a pandas udf from it\n",
    "* See [pandas_udf](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.pandas_udf.html#pyspark.sql.functions.pandas_udf) in the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd191be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pandas udf \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05922850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the UDF:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3ded3",
   "metadata": {},
   "source": [
    "## Compare the performace for both UDFs\n",
    "### Hint\n",
    "\n",
    "* run the query with the noop format and write it to make sure all transformations are executed\n",
    "* use Python time module to define the start_time and end_time so you can subtract them and compute the execution time for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ea4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of vanilla UDF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of Pandas UDF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b4cfa-020f-498c-8238-ef5ca2b37943",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
