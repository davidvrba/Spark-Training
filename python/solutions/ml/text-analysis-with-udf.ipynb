{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3a9ae3-7e38-42d7-a656-086977ed1d2f",
   "metadata": {},
   "source": [
    "# Find similar question\n",
    "\n",
    "Using a Python library for NLP compute sentence embeddings for each question and then using cosine similarity find the most similar question to a reference question.\n",
    "\n",
    "See the [docs](https://pypi.org/project/sentence-transformers/) for sentence_transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cb1d9-9654-4d51-ae1b-7b1229a4f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, regexp_replace, trim, desc, lit, concat, expr, udf\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c18e7f-6104-4f10-8f7f-6c4ba6c8cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('Text similarity with UDF')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7e51d-86aa-4081-8489-c98f44b33c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "project_path = ('/').join(base_path.split('/')[0:-3]) \n",
    "\n",
    "questions_json_input_path = os.path.join(project_path, 'data/questions-json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef77b6f7-0334-4439-8d01-ca3aaf94b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsDF = (\n",
    "    spark\n",
    "    .read\n",
    "    .format('json')\n",
    "    .option('path', questions_json_input_path)\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8324687-88ea-4c00-a5e6-8fd4c51a7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to clean the text and remove html tags with other symbols\n",
    "\n",
    "def clean_text(df: DataFrame) -> DataFrame:\n",
    "    return (\n",
    "        df.withColumn('body', regexp_replace('body', '<[^>]*>', ''))  # Remove HTML tags\n",
    "        .withColumn('body', regexp_replace('body', '\\\\\\\\n|\\\\\\\\r|\\\\\\\\t|\\\\n|\\\\r|\\\\t', ' '))  # Remove escape characters\n",
    "        .withColumn('body', regexp_replace('body', '\\\\s+', ' '))  # Collapse multiple spaces\n",
    "        .withColumn('body', trim('body'))  # Trim leading/trailing spaces\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c9ffe-3581-421f-bf0e-a0dc6e32e5f2",
   "metadata": {},
   "source": [
    "1) Apply the clean_text function on the questions data.\n",
    "2) Next create a new column `title` in which you concat `title` with the `body` of the question to have more context for the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7249004-6d55-4220-8a90-99c044714f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionsDF = (\n",
    "    questionsDF\n",
    "    .transform(clean_text)\n",
    "    .withColumn('title', concat('title', lit(': '), 'body'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c79a1b-1866-4758-a14a-d15b76fd0048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the all-MiniLM-L6-v2 model:\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aad042-1e00-48cb-b341-6bd76d3e1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the reference question which you need to compare with all other questions in the questions DataFrame:\n",
    "\n",
    "reference_question = 'How can I get the first and last row of each partition in PySpark after using repartition and sortWithinPartitions?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946bab3-b775-44f4-b5ab-d9c5114a77ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the embedding for the reference question and convert it to list:\n",
    "\n",
    "reference_embedding = model.encode(reference_question).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21cf645-39ed-4a30-b1e7-be14b0483174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the udf to compute embedding for the questions in the DataFrame:\n",
    "# The UDF should return array of doubles\n",
    "\n",
    "@udf(ArrayType(DoubleType()))\n",
    "def get_embeddings_udf(text):\n",
    "    return model.encode(text).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900c4875-6586-4963-999c-97765fa24d7d",
   "metadata": {},
   "source": [
    "1) First filter the questions DataFrame to questions where the tags contain the expression `spark`. This will speed up the calculation as computing the embeddings for the whole DataFrame takes about 0.5h. After the filter it should be around 0.5min.\n",
    "\n",
    "2) Next, compute the embedding for each question using the UDF.\n",
    "\n",
    "3) Add the embedding for the reference question as a new column to the DataFrame. Then compute the similarity between the reference question and all other questions.\n",
    "\n",
    "This SQL expression with higher order functions can calculate the cosine similarity for two normalized vectors. The model is returning normalized vectors, so no additinoal normalization is required. Make sure `embedding` and `ref_embedding` are columns in the DataFrame and contain the arrays of doubles for the embeddings of the two questions for which you want to compute the similarity.\n",
    "```\n",
    "aggregate(\n",
    "    zip_with(embedding, ref_embedding, (x, y) -> x * y),\n",
    "    0D,\n",
    "    (acc, x) -> acc + x\n",
    ")\n",
    "```\n",
    "4) Finaly sort the result in desc order by the computed similarity and find the questions that is more similar to the reference question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa8c93-fc46-4ec7-aca1-e3e492d660e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "\n",
    "(\n",
    "    questionsDF\n",
    "    .filter(col('tags').like('%spark%'))\n",
    "    .withColumn('embedding', get_embeddings_udf('title'))\n",
    "    .withColumn('ref_embedding', lit(reference_embedding))\n",
    "    .withColumn(\n",
    "        'similarity', \n",
    "        expr(\"\"\"\n",
    "          aggregate(\n",
    "            zip_with(embedding, ref_embedding, (x, y) -> x * y),\n",
    "            0D,\n",
    "            (acc, x) -> acc + x\n",
    "          )\n",
    "        \"\"\")\n",
    "    )\n",
    "    .orderBy(desc('similarity'))\n",
    "    .select('title', 'similarity')\n",
    ").show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc729caf-cff5-489d-93ad-47909c50e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
